{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_pipeline.np_dataset import NpDataset\n",
    "import input_mapping.models_torch as models_torch\n",
    "from data_pipeline.image_transforms import get_transforms\n",
    "\n",
    "from data_pipeline.data_package import DataPackage\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from pydicom import dcmread\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "from ai_backend.loggers.model_logger import is_min\n",
    "from uuid import uuid4\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import tqdm\n",
    "from ai_backend.evaluators.metrics.multi_label_metrics import  multi_label_f_beta, multi_label_confusion_matrix, multi_label_accuracy, multi_label_precision, multi_label_recall\n",
    "import numpy as np\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, multilabel_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = '78cce3e7-29cf-4bf8-a557-fbf4c1ad8ec9'\n",
    "model_key = 'resnet18'\n",
    "model_folder = f'models/{model_key}/{model_id}'\n",
    "path_to_model_conig = f'{model_folder}/run_config.json'\n",
    "#load the model configuration\n",
    "with open(path_to_model_conig, 'r') as f:\n",
    "    run_config = json.load(f)\n",
    "#also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_type = run_config['transform_type']\n",
    "transforms_config = models_torch.model_dict[model_key]['transforms_config']\n",
    "transform = get_transforms(transform_name = transform_type, transforms_config = transforms_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model\n",
    "dataset_name = '2024-06-05_16-22-01'\n",
    "#load the dataset configuration\n",
    "path_to_dataset_config = f'datasets/{dataset_name}/dataset_config.json'\n",
    "\n",
    "with open(path_to_dataset_config, 'r') as f:\n",
    "    dataset_config = json.load(f)\n",
    "#get the the labels\n",
    "labels_to_encode = dataset_config['labels_to_encode']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_save_folder = f'models/{model_key}/{model_id}'\n",
    "best_model_save_path = f'{best_model_save_folder}/weights.pth'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#create np datasets for training, validation and testing\n",
    "read_dicom = lambda x: dcmread(x).pixel_array\n",
    "dicom_file_reader = lambda x: Image.fromarray(read_dicom(x)).convert('RGB')\n",
    "default_file_reader = lambda x: Image.open(x).convert('RGB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_package_to_dataset(package, augmentations=None):\n",
    "    file_reader = dicom_file_reader if package.data_source_name == 'UKB' else default_file_reader\n",
    "    dataset = NpDataset(file_paths=package.get_data(), labels=package.get_labels(),\n",
    "                         file_reader=file_reader, transform=transform, augmentation_transform=augmentations)\n",
    "    return dataset\n",
    "\n",
    "def convert_package_list_to_dataset(package_list, augmentations=None):\n",
    "    datasets = []\n",
    "    for package in package_list:\n",
    "        dataset = convert_package_to_dataset(package)\n",
    "        datasets.append(dataset)\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list the saved directories and load the datapackages\n",
    "dataset_path = 'datasets/2024-06-05_16-22-01'\n",
    "test_packages_path = f'{dataset_path}/test'\n",
    "test_packages_paths = os.listdir(test_packages_path)\n",
    "test_packages = []\n",
    "for package_path in test_packages_paths:\n",
    "    test_packages.append(DataPackage.load(f'{test_packages_path}/{package_path}'))\n",
    "test_dataset = convert_package_list_to_dataset(test_packages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#create data loaders\n",
    "num_workers = 4\n",
    "#create the data loaders\n",
    "batch_size = 512\n",
    "data_loaders = []\n",
    "for dataset in test_dataset:\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    data_loaders.append(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efarjall/miniconda3/envs/ird/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/efarjall/miniconda3/envs/ird/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = models_torch.get_model(model_name=model_key, num_classes=len(labels_to_encode))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding forward hook for: layer1\n",
      "Adding forward hook for: layer2\n",
      "Adding forward hook for: layer3\n",
      "Adding forward hook for: layer4\n"
     ]
    }
   ],
   "source": [
    "#add dropout forward hooks to the model\n",
    "for name, module in model.named_modules():\n",
    "    re_pattern = re.compile(r'^layer\\d+$')\n",
    "    if re_pattern.match(name) is not None:\n",
    "        print('Adding forward hook for:', name)\n",
    "        module.register_forward_hook(lambda module, input,\n",
    "                                      output: torch.nn.functional.dropout2d(output, p=0.2, training=module.training))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the best model\n",
    "model.load_state_dict(torch.load(best_model_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sread the best thresholds\n",
    "with open(f'{best_model_save_folder}/best_thresholds.json', 'r') as f:\n",
    "    best_thresholds = json.load(f)\n",
    "#convert to tensor\n",
    "best_thresholds = torch.tensor(best_thresholds, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate the model\n",
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "for test_loader in data_loaders:\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for i, data in enumerate(test_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        y_true.append(labels.cpu().detach())\n",
    "        y_pred.append(outputs.cpu().detach())\n",
    "    y_true = torch.concat(y_true, dim=0)\n",
    "    y_pred = torch.concat(y_pred, dim=0)\n",
    "    y_true_list.append(y_true)\n",
    "    y_pred_list.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "['Age-related Macular Degeneration', 'Best Disease', 'Bietti crystalline dystrophy', 'cataract', 'Cone Dystrophy or Cone-rod Dystrophy', 'Diabetic Retinopathy', 'glaucoma', 'Maculopathy', 'Myopia', 'Normal', 'Retinitis Pigmentosa', 'Stargardt Disease', 'Macular dystrophy', 'Pseudoxanthoma elasticum', 'Retinal Dystrophy', 'Optic atrophy', 'Usher-Syndrom', 'Drusen', 'Leber Hereditary Optic Neuropathy', 'Choroideremia', 'Sorsby Fundus Dystrophy']\n"
     ]
    }
   ],
   "source": [
    "print(best_thresholds)\n",
    "print(labels_to_encode)\n",
    "best_thresholds = best_thresholds.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efarjall/IRD-DeepLearning/ai_backend/evaluators/metrics/multi_label_metrics.py:115: RuntimeWarning: invalid value encountered in divide\n",
      "  recall = true_positives / (true_positives + false_negatives)\n",
      "/home/efarjall/IRD-DeepLearning/ai_backend/evaluators/metrics/multi_label_metrics.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  f_beta = (1 + beta**2) * (precision * recal) / ((beta**2 * precision) + recal)\n",
      "/home/efarjall/IRD-DeepLearning/ai_backend/evaluators/metrics/multi_label_metrics.py:115: RuntimeWarning: invalid value encountered in divide\n",
      "  recall = true_positives / (true_positives + false_negatives)\n",
      "/home/efarjall/IRD-DeepLearning/ai_backend/evaluators/metrics/multi_label_metrics.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  f_beta = (1 + beta**2) * (precision * recal) / ((beta**2 * precision) + recal)\n",
      "/home/efarjall/IRD-DeepLearning/ai_backend/evaluators/metrics/multi_label_metrics.py:115: RuntimeWarning: invalid value encountered in divide\n",
      "  recall = true_positives / (true_positives + false_negatives)\n",
      "/home/efarjall/IRD-DeepLearning/ai_backend/evaluators/metrics/multi_label_metrics.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  f_beta = (1 + beta**2) * (precision * recal) / ((beta**2 * precision) + recal)\n",
      "/home/efarjall/IRD-DeepLearning/ai_backend/evaluators/metrics/multi_label_metrics.py:115: RuntimeWarning: invalid value encountered in divide\n",
      "  recall = true_positives / (true_positives + false_negatives)\n",
      "/home/efarjall/IRD-DeepLearning/ai_backend/evaluators/metrics/multi_label_metrics.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  f_beta = (1 + beta**2) * (precision * recal) / ((beta**2 * precision) + recal)\n",
      "/home/efarjall/IRD-DeepLearning/ai_backend/evaluators/metrics/multi_label_metrics.py:115: RuntimeWarning: invalid value encountered in divide\n",
      "  recall = true_positives / (true_positives + false_negatives)\n",
      "/home/efarjall/IRD-DeepLearning/ai_backend/evaluators/metrics/multi_label_metrics.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  f_beta = (1 + beta**2) * (precision * recal) / ((beta**2 * precision) + recal)\n",
      "/home/efarjall/IRD-DeepLearning/ai_backend/evaluators/metrics/multi_label_metrics.py:115: RuntimeWarning: invalid value encountered in divide\n",
      "  recall = true_positives / (true_positives + false_negatives)\n",
      "/home/efarjall/IRD-DeepLearning/ai_backend/evaluators/metrics/multi_label_metrics.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  f_beta = (1 + beta**2) * (precision * recal) / ((beta**2 * precision) + recal)\n",
      "/home/efarjall/IRD-DeepLearning/ai_backend/evaluators/metrics/multi_label_metrics.py:115: RuntimeWarning: invalid value encountered in divide\n",
      "  recall = true_positives / (true_positives + false_negatives)\n",
      "/home/efarjall/IRD-DeepLearning/ai_backend/evaluators/metrics/multi_label_metrics.py:182: RuntimeWarning: invalid value encountered in divide\n",
      "  f_beta = (1 + beta**2) * (precision * recal) / ((beta**2 * precision) + recal)\n"
     ]
    }
   ],
   "source": [
    "#calculate the metrics\n",
    "f1_dicts = []\n",
    "for i in range(len(y_true_list)):\n",
    "    y_true = y_true_list[i]\n",
    "    y_pred = y_pred_list[i]\n",
    "    f1 = multi_label_f_beta(y_true, y_pred, threshold=best_thresholds, beta=1.0)\n",
    "    f1_dict = {label: f1_value for label, f1_value in zip(labels_to_encode, f1)}\n",
    "    f1_dicts.append(f1_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RP F1 scores: [nan, 0.01639344262295082, 0.02985074626865672, 0.1492537313432836, 1.0, 0.7804878048780487, 0.550561797752809]\n"
     ]
    }
   ],
   "source": [
    "rp_f1_scores = []\n",
    "for f1_dict in f1_dicts:\n",
    "    rp_f1_score = f1_dict['Retinitis Pigmentosa']\n",
    "    rp_f1_scores.append(rp_f1_score)\n",
    "print(f'RP F1 scores: {rp_f1_scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the Retinitis Pigmentosa f1 scores from the f1_dicts\n",
    "#create a pandas dataframe which contains the f1 scores of the Retinitis Pigmentosa\n",
    "#reshape rp f1 scores\n",
    "rp_f1_scores = np.array(rp_f1_scores)\n",
    "column_names = [package.data_source_name for package in test_packages]\n",
    "#create a dictionary matching the column names to the rp f1 scores\n",
    "rp_f1_dict = {column_name: rp_f1_score for column_name, rp_f1_score in zip(column_names, rp_f1_scores)}\n",
    "rp_f1_df = pd.DataFrame(rp_f1_dict, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the odir5k column\n",
    "rp_f1_df = rp_f1_df.drop('ODIR-5K', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1000images</th>\n",
       "      <th>BAU</th>\n",
       "      <th>RFMiD</th>\n",
       "      <th>RFMiD2</th>\n",
       "      <th>RIPS</th>\n",
       "      <th>UKB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1000images   BAU  RFMiD  RFMiD2  RIPS   UKB\n",
       "0        0.15  0.78   0.02    0.03   1.0  0.55"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#rename SES to BAU\n",
    "rp_f1_df = rp_f1_df.rename(columns={'SES': 'BAU'})\n",
    "#sort the columns alphabetically\n",
    "rp_f1_df = rp_f1_df.reindex(sorted(rp_f1_df.columns), axis=1)\n",
    "rp_f1_df.round(2).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ird",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
