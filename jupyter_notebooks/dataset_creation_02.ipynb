{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from data_pipeline.ukb_data_extractor import UkbDataExtractor\n",
    "import data_pipeline.data_processing_utils as dpu\n",
    "from data_pipeline.odir_5k_data_extractor import ODIR5KDataExtractor\n",
    "from data_pipeline.rfmid_data_extractor import RFMiDDataExtractor\n",
    "from data_pipeline.rfmid2_data_extractor import RFMiD2DataExtractor\n",
    "from data_pipeline.ukb_data_extractor import UkbDataExtractor\n",
    "from data_pipeline.rips_data_extractor import RIPSDataExtractor\n",
    "from data_pipeline.ses_data_extractor import SESDataExtractor\n",
    "from data_pipeline.one_thousand_images_data_extractor import OneThousandImagesDataExtractor\n",
    "from data_pipeline.data_processing_utils import standardize_labels\n",
    "import data_pipeline.data_processing_utils as dpu\n",
    "\n",
    "import numpy as np\n",
    "from uuid import uuid4\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_name = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "dataset_path = f'datasets/{dataset_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_encode = np.array([\"Age-related Macular Degeneration\", \"Best Disease\", \"Bietti crystalline dystrophy\",\n",
    "                              \"cataract\", \"Cone Dystrophie or Cone-rod Dystrophie\", \"Diabetic Retinopathy\",\n",
    "                              \"glaucoma\", \"Maculopathy\", \"Myopia\", \"Normal\", \"Retinitis Pigmentosa\", \"Stargardt Disease\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ukb_database_path = 'databases/ird_dataset/IRD-Dataset-Complete-03-anonymized.xlsx'\n",
    "ukb_data_path ='databases/ird_dataset/export_heyex_original_dataset_03/DICOM'\n",
    "ukb_extractor = UkbDataExtractor(database_path=ukb_data_path, label_path=ukb_database_path)\n",
    "\n",
    "odir5k_data_extractor = ODIR5KDataExtractor(database_path='databases/ODIR-5K/full_df.csv', database_test_images_path='databases/ODIR-5K/Testing Images',\n",
    "                                                database_train_images_path='databases/ODIR-5K/Training Images')\n",
    "\n",
    "rfmid_train_data_extractor = RFMiDDataExtractor(database_path='databases/RFMiD/Training_Set/RFMiD_Training_Labels.csv',\n",
    "                                            data_path='databases/RFMiD/Training_Set/Training', file_format='png')\n",
    "\n",
    "rfmid_validation_datae_xtractor = RFMiDDataExtractor(database_path='databases/RFMiD/Evaluation_Set/RFMiD_Validation_Labels.csv',\n",
    "                                            data_path='databases/RFMiD/Evaluation_Set/Validation', file_format='png')\n",
    "\n",
    "rfmid_test_data_extractor = RFMiDDataExtractor(database_path='databases/RFMiD/Test_Set/RFMiD_Testing_Labels.csv',\n",
    "                                                data_path='databases/RFMiD/Test_Set/Test', file_format='png')\n",
    "\n",
    "rfmid2_train_data_extractor = RFMiD2DataExtractor(database_path='databases/RFMiD2_0/Training_set/RFMiD_2_Training_labels.csv',\n",
    "                                                    data_path='databases/RFMiD2_0/Training_set')\n",
    "rfmid2_validation_data_extractor = RFMiD2DataExtractor(database_path='databases/RFMiD2_0/Validation_set/RFMiD_2_Validation_labels.csv',\n",
    "                                                            data_path='databases/RFMiD2_0/Validation_set')\n",
    "\n",
    "rfmid2_test_data_extractor = RFMiD2DataExtractor(database_path='databases/RFMiD2_0/Test_set/RFMiD_2_Testing_labels.csv',\n",
    "                                                        data_path='databases/RFMiD2_0/Test_set')\n",
    "\n",
    "\n",
    "one_thousand_images_data_extractor = OneThousandImagesDataExtractor(database_path='databases/1000images/')\n",
    "\n",
    "rips_data_extractor = RIPSDataExtractor(database_path='databases/RIPS/Original')\n",
    "\n",
    "ses_data_extractor = SESDataExtractor(database_path='databases/SES/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the data extraction list\n",
    "default_data_extractors = [odir5k_data_extractor, rfmid_train_data_extractor, rfmid_validation_datae_xtractor, rfmid_test_data_extractor,\n",
    "                    rfmid2_train_data_extractor, rfmid2_validation_data_extractor, rfmid2_test_data_extractor,\n",
    "                    one_thousand_images_data_extractor, rips_data_extractor, ses_data_extractor]\n",
    "\n",
    "dicom_data_extractors = [ukb_extractor]\n",
    "\n",
    "data_extractors = default_data_extractors + dicom_data_extractors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the data\n",
    "for data_extractor in data_extractors:\n",
    "    data_extractor.extract()\n",
    "\n",
    "#standardize the data\n",
    "#get the labels of the data\n",
    "datasets_labels = []\n",
    "for data_extractor in data_extractors:\n",
    "    datasets_labels.append(data_extractor.get_labels())\n",
    "#flatten\n",
    "labels = []\n",
    "for dataset_labels in datasets_labels:\n",
    "    labels.extend(dataset_labels)\n",
    "#concatenate the labels\n",
    "labels = np.concatenate(labels)\n",
    "#drop the None values\n",
    "labels = labels[labels != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_summarize_set = set(RFMiD2DataExtractor.abbreviation_map.values())\n",
    "ukb_label_mapping_dict = {'Morbus Best': 'Best Disease', 'Morbus Stargardt': 'Stargardt Disease', 'Retinitis pigmentosa': 'Retinitis Pigmentosa', 'Morbus Stargardt ': 'Stargardt Disease'}\n",
    "label_standertizer = standardize_labels(labels = labels, not_summarize_set=not_summarize_set)\n",
    "label_standertizer.update(ukb_label_mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CSNB ': 'CSNB', 'drusen': 'Drusen', 'Drusen ': 'Drusen', 'Drusens': 'Drusen', 'myopia retinopathy': 'Myopia', 'Pathological myopia': 'Myopia', 'pathological myopia': 'Myopia', 'normal fundus': 'Normal', 'Optic atrophy': 'atrophy', 'optic nerve atrophy': 'atrophy', 'chorioretinal atrophy': 'atrophy', 'peripapillary atrophy': 'atrophy', 'diffuse retinal atrophy': 'atrophy', 'oval yellow-white atrophy': 'atrophy', 'diffuse chorioretinal atrophy': 'atrophy', 'Chorioretinal atrophy-coloboma': 'Coloboma', 'retinal pigment epithelium atrophy': 'atrophy', 'chorioretinal atrophy with pigmentation proliferation': 'atrophy', 'macular coloboma': 'Coloboma', 'retinochoroidal coloboma': 'Coloboma', 'congenital choroidal coloboma': 'Coloboma', 'Retinitis pigmentosa': 'Retinitis Pigmentosa', 'retinitis pigmentosa': 'Retinitis Pigmentosa', 'Laser Spots': 'laser spot', 'maculopathy': 'Maculopathy', 'myopic maculopathy': 'Maculopathy', 'Optic Disc Pit Maculopathy': 'Maculopathy', 'low image quality,maculopathy': 'low image quality', 'Morbus Best ': 'Morbus Best', 'macular hole': 'Macular Hole', 'Usher-Syndrom ': 'Usher-Syndrom', 'Makuladystrophie ': 'Makuladystrophie', ' Makuladystrophie ': 'Makuladystrophie', 'optic disc edema': 'Optic Disc Edema', 'Cotton-wool spots': 'Cotton-Wool Spots', 'vessel tortuosity': 'Vessel tortuosity', 'retinal detachment': 'Retinal Detachment', 'tessellated fundus': 'Tessellated fundus', 'epiretinal membrane': 'Epiretinal Membrane', 'macular epiretinal membrane': 'Epiretinal Membrane', 'optic disk epiretinal membrane': 'Epiretinal Membrane', 'epiretinal membrane over the macula': 'Epiretinal Membrane', 'diabetic retinopathy': 'Diabetic Retinopathy', 'proliferative diabetic retinopathy': 'Diabetic Retinopathy', 'severe proliferative diabetic retinopathy': 'Diabetic Retinopathy', 'hypertensive retinopathy,diabetic retinopathy': 'hypertensive retinopathy', 'Preretinal hemorrhage': 'Preretinal Hemorrhage', 'macular pigmentation disorder': 'pigmentation disorder', 'Myelinated Nerve Fibers': 'Myelinated nerve fiber', 'myelinated nerve fibers': 'Myelinated nerve fiber', 'Severe hypertensive retinopathy': 'hypertensive retinopathy', 'branch retinal vein occlusion': 'Branch Retinal Vein Occlusion', 'old branch retinal vein occlusion': 'Branch Retinal Vein Occlusion', 'central retinal vein occlusion': 'Central Retinal Vein Occlusion', 'old central retinal vein occlusion': 'Central Retinal Vein Occlusion', 'branch retinal artery occlusion': 'Branch Retinal Artery Occlusion', 'age-related macular degeneration': 'Age-related Macular Degeneration', 'dry age-related macular degeneration': 'Age-related Macular Degeneration', 'wet age-related macular degeneration': 'Age-related Macular Degeneration', 'central retinal artery occlusion': 'Central Retinal Artery Occlusion', 'Morbus Best': 'Best Disease', 'Morbus Stargardt': 'Stargardt Disease', 'Morbus Stargardt ': 'Stargardt Disease'}\n"
     ]
    }
   ],
   "source": [
    "print(label_standertizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['low image quality,maculopathy', 'hypertensive retinopathy,diabetic retinopathy']\n"
     ]
    }
   ],
   "source": [
    "#find all keys that contain a ,\n",
    "keys_with_comma = [key for key in label_standertizer.keys() if ',' in key]\n",
    "print(keys_with_comma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#value count the labels\n",
    "label_counts = pd.Series(labels).value_counts()\n",
    "#get the median label count\n",
    "median_label_count = label_counts.median()\n",
    "label_instance_limit = int((max(label_counts) - median_label_count) // 4)\n",
    "#balance the labels\n",
    "#find the over represented labels\n",
    "for labels,extractor in zip(datasets_labels, data_extractors):\n",
    "    #find the over represented labels\n",
    "    #replace none with empty string\n",
    "    over_represented_labels_idxs, _, _ = dpu.find_over_represented_samples(file_paths=extractor.get_file_paths(), labels=labels,\n",
    "                                                                            max_samples_per_class=label_instance_limit)\n",
    "    #remove the over represented labels\n",
    "    #conver the indexes to a boolean array\n",
    "    over_represented_labels_series = np.isin(np.arange(len(labels)), over_represented_labels_idxs)\n",
    "    extractor.extracted_data = extractor.extracted_data[~over_represented_labels_series]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data stratified by the labels\n",
    "train_portion = 0.7\n",
    "val_portion = 0.1\n",
    "test_portion = 0.2\n",
    "split_portions = [train_portion, val_portion, test_portion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = []\n",
    "for data_extractor in data_extractors:\n",
    "    splits.extend(data_extractor.split_extracted_data(split_portions = split_portions, stratify=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_strip = lambda x: x.strip() if isinstance(x, str) else x\n",
    "label_translation = lambda x: label_standertizer.get(x, x)\n",
    "for i, split in enumerate(splits):\n",
    "    #strip trailing and leading whitespaces\n",
    "    #split.labels = np.vectorize(lambda_strip)(split.labels)\n",
    "    split.labels = np.vectorize(label_translation)(split.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all the labels\n",
    "all_labels = []\n",
    "for split in splits:\n",
    "    all_labels.extend(split.labels)\n",
    "#create set of all labels\n",
    "all_labels = np.concatenate(all_labels)\n",
    "#filter out the None values\n",
    "all_labels = all_labels[all_labels != None]\n",
    "all_labels = np.unique(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = dpu.create_one_hot_encoder(unique_labels=labels_to_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in splits:\n",
    "    split.labels = dpu.encode_multistring_labels(split.labels, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2977\n"
     ]
    }
   ],
   "source": [
    "print(len(splits[0].get_labels()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ODIR-5K\n",
      "n filtered 1641 out of 2977\n",
      "ODIR-5K\n",
      "n filtered 232 out of 425\n",
      "ODIR-5K\n",
      "n filtered 467 out of 850\n",
      "RFMiD\n",
      "n filtered 671 out of 1341\n",
      "RFMiD\n",
      "n filtered 103 out of 200\n",
      "RFMiD\n",
      "n filtered 189 out of 379\n",
      "RFMiD\n",
      "n filtered 215 out of 444\n",
      "RFMiD\n",
      "n filtered 34 out of 66\n",
      "RFMiD\n",
      "n filtered 64 out of 130\n",
      "RFMiD\n",
      "n filtered 225 out of 448\n",
      "RFMiD\n",
      "n filtered 33 out of 64\n",
      "RFMiD\n",
      "n filtered 63 out of 128\n",
      "RFMiD2\n",
      "n filtered 178 out of 310\n",
      "RFMiD2\n",
      "n filtered 30 out of 50\n",
      "RFMiD2\n",
      "n filtered 57 out of 95\n",
      "RFMiD2\n",
      "n filtered 59 out of 106\n",
      "RFMiD2\n",
      "n filtered 9 out of 15\n",
      "RFMiD2\n",
      "n filtered 21 out of 35\n",
      "RFMiD2\n",
      "n filtered 63 out of 104\n",
      "RFMiD2\n",
      "n filtered 10 out of 16\n",
      "RFMiD2\n",
      "n filtered 16 out of 29\n",
      "1000images\n",
      "n filtered 561 out of 699\n",
      "1000images\n",
      "n filtered 81 out of 100\n",
      "1000images\n",
      "n filtered 162 out of 201\n",
      "RIPS\n",
      "n filtered 0 out of 60\n",
      "RIPS\n",
      "n filtered 0 out of 30\n",
      "RIPS\n",
      "n filtered 0 out of 30\n",
      "SES\n",
      "n filtered 2 out of 87\n",
      "SES\n",
      "n filtered 0 out of 12\n",
      "SES\n",
      "n filtered 0 out of 26\n",
      "UKB\n",
      "n filtered 745 out of 1427\n",
      "UKB\n",
      "n filtered 90 out of 204\n",
      "UKB\n",
      "n filtered 225 out of 407\n"
     ]
    }
   ],
   "source": [
    "#find out which datapoints have a full 0 label\n",
    "for split in splits:\n",
    "    print(split.data_source_name)\n",
    "    labels = split.get_labels()\n",
    "    no_zero_labels = np.sum(labels, axis=1) != 0\n",
    "    #print len false values\n",
    "    print('n filtered', len(no_zero_labels) - np.sum(no_zero_labels), 'out of', len(no_zero_labels))\n",
    "    #throw away the datapoints with no labels\n",
    "    split.labels = labels[no_zero_labels]\n",
    "    split.data = split.data[no_zero_labels]\n",
    "    split.instance_ids = split.instance_ids[no_zero_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1336"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(default_data_extractors[0].get_current_split()[0].get_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape the splits list so that always 3 splits are in a row\n",
    "buffer = []\n",
    "for i in range(0, len(splits), 3):\n",
    "    inner_list = splits[i:i + 3]\n",
    "    buffer.append(inner_list)\n",
    "splits = buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "dataset_path = f'datasets/{time}'\n",
    "train_datas_save_path = f'{dataset_path}/train'\n",
    "val_datas_save_path = f'{dataset_path}/val'\n",
    "test_datas_save_path = f'{dataset_path}/test'\n",
    "save_path_list = [train_datas_save_path, val_datas_save_path, test_datas_save_path]\n",
    "os.makedirs(train_datas_save_path, exist_ok=True)\n",
    "os.makedirs(val_datas_save_path, exist_ok=True)\n",
    "os.makedirs(test_datas_save_path, exist_ok=True)\n",
    "#crearte a dataset configuration\n",
    "dataset_config = {'labels_to_encode': labels_to_encode, 'label_standertizer': label_standertizer}\n",
    "with open(f'{dataset_path}/dataset_config.json', 'w') as f:\n",
    "    json.dump(dataset_config, f)\n",
    "for split in splits:\n",
    "    for package, path in zip(split, save_path_list):\n",
    "        total_path = f'{path}/{package.data_source_name}.json'\n",
    "        #check if the path already exists\n",
    "        if os.path.exists(total_path):\n",
    "            #if it exists, append a uuid to the path\n",
    "            total_path = f'{path}/{package.data_source_name}_{str(uuid4())[:4]}.json'\n",
    "        package.save(f'{total_path}')\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ird_deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
