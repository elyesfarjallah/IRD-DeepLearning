{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models import resnet152, ResNet152_Weights\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from trainer import train\n",
    "import json\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store current time\n",
    "date_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import resnet\n",
    "resnet_model = resnet152(weights = ResNet152_Weights.DEFAULT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RectAngularPadTransform(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, img):\n",
    "        padding = (\n",
    "            max(0, (img.size[1] - img.size[0]) // 2),\n",
    "            max(0, (img.size[0] - img.size[1]) // 2)\n",
    "        )\n",
    "        #show image\n",
    "        new_img = new_img = F.pad(img, padding)\n",
    "        return new_img\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#transform images for resnet\n",
    "transform = transforms.Compose([\n",
    "    RectAngularPadTransform(),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std=[0.229,0.224,0.225])\n",
    "])\n",
    "#load data\n",
    "dataset_path = 'datasets/2023-12-08-16-54'\n",
    "dataset = ImageFolder(root=dataset_path, transform=transform)\n",
    "targets = dataset.targets\n",
    "#split data into train, test, val\n",
    "#70-20-10\n",
    "train_val_idx, test_idx= train_test_split(np.arange(len(targets)),test_size=0.2,shuffle=True,stratify=targets, random_state=42)\n",
    "print(type(train_val_idx))\n",
    "train_val_idx_list = train_val_idx.tolist()\n",
    "train_val_stratifier = np.take(targets,train_val_idx_list)\n",
    "#targets[train_val_idx_list]\n",
    "train_idx, validation_idx = train_test_split(train_val_idx,test_size=0.125,shuffle=True,stratify=train_val_stratifier, random_state=42)\n",
    "#adjust classifier to match number of classes +1 for uncertain\n",
    "resnet_model.fc = nn.Linear(2048, len(dataset.classes))\n",
    "#load data into dataloader\n",
    "batch_size = 64\n",
    "\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "validation_sampler = torch.utils.data.SubsetRandomSampler(validation_idx)\n",
    "test_sampler = torch.utils.data.SubsetRandomSampler(test_idx)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=validation_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resnet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of train samples: \", len(train_idx), (len(train_loader.sampler)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_loader_class_distribution(loader: DataLoader, title : str):\n",
    "    #plot class distribution in dataset\n",
    "    class_counts = {class_idx: 0 for class_idx in range(len(dataset.classes))}\n",
    "\n",
    "    # Count the number of samples in each class in train dataloader\n",
    "    for _, label in train_loader:\n",
    "        for class_idx in label:\n",
    "            print(class_idx.item())\n",
    "            class_counts[class_idx.item()] += 1\n",
    "    # Plot the distribution\n",
    "    classes = [dataset.classes[idx] for idx in class_counts.keys()]\n",
    "    counts = [class_counts[idx] for idx in class_counts.keys()]\n",
    "\n",
    "    plot = plt.bar(classes, counts)\n",
    "    plt.xlabel('Classes')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45, ha=\"right\")  # Rotate x-axis labels for better readability\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    plot_data_loader_class_distribution(train_loader, 'Train Data Class Distribution')\n",
    "    plt.savefig(f'dataset_plots/{date_time}/train_data.png')\n",
    "    plt.show()\n",
    "    plot_data_loader_class_distribution(validation_loader, 'Validation Data Class Distribution')\n",
    "    plt.savefig(f'dataset_plots/{date_time}/validation_data.png')\n",
    "    plt.show()\n",
    "    plot_data_loader_class_distribution(test_loader, 'Test Data Class Distribution')\n",
    "    plt.savefig(f'dataset_plots/{date_time}/test_data.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "#plot one example with and without the transform\n",
    "#pathn to example image\n",
    "path = 'datasets/2023-12-07-12-57/age-related macular degeneration/43_left.jpg'\n",
    "img = cv2.imread(path)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "print(img_rgb.shape)\n",
    "#show image\n",
    "plt.imshow(img_rgb)\n",
    "plt.show()\n",
    "#transform image to tensor\n",
    "pil_img = Image.open(path).convert('RGB')\n",
    "pil_img = transform(pil_img)\n",
    "#show image\n",
    "plt.imshow(pil_img.permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet_model\n",
    "n_classes = len(dataset.classes) #+ 1\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "lr = 0.001\n",
    "dataset_path = dataset_path\n",
    "best_weights_save_path = f'models/{date_time}_{resnet_model.__class__.__name__}.pth'\n",
    "train_loader = train_loader\n",
    "validation_loader = validation_loader\n",
    "\n",
    "#train model\n",
    "model_history_dict = train(model=model, n_classes=n_classes, batch_size=batch_size, epochs=epochs, lr=lr, dataset_path=dataset_path, best_weights_save_path=best_weights_save_path, train_loader=train_loader, validation_loader=validation_loader)\n",
    "print(model_history_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model history dict to json file\n",
    "with open(f'{best_weights_save_path}.json', 'w') as fp:\n",
    "    json.dump(model_history_dict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_accuracy = max(model_history_dict['validation']['accuracy'])\n",
    "print(f'Best validation accuracy: {best_val_accuracy}', 'n_classes', n_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ird",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
